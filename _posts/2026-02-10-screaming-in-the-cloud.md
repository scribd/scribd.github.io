---
layout: post
title: "Screaming in the Cloud"
tags:
- aws
- featured
author: rtyler
team: Infrastructure Engineering
---


Scribd has absolutely fascinating data-at-scale type problems, all the way
down to the fundamentals of how we use AWS S3. In my [previous
post](/blog/2026/content-crush.html) I wrote about the design of Content
Crush and how Scribd is consolidating objects in S3 to minimize our costs.
Related to that work I was fortunate enough to join the (in)famous [Corey
Quinn](https://www.linkedin.com/in/coquinn/) to talk about **Engineering around Extreme S3 scale**:

_Checking if files are damaged? $100K. Using newer S3 tools? Way too expensive.
Normal solutions don't work anymore. Tyler shares how with this much data, you
can't just throw money at the problem, but rather you have to engineer your way
out._

<iframe width="560" height="315" src="https://www.youtube-nocookie.com/embed/TZj38Bm1DC4?si=m_jo0HOFPHqPC--2" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>


You can also listen
[On Everand](https://www.everand.com/podcast/980476250/Engineering-Around-Extreme-S3-Scale-with-R-Tyler-Croy)
or watch via the 
[Last Week in AWS YouTube channel](https://www.youtube.com/watch?v=TZj38Bm1DC4)
